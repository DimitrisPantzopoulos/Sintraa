{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>Stock Remaining (%)</th>\n",
       "      <th>Avg_consumption Rate (%)</th>\n",
       "      <th>Price</th>\n",
       "      <th>AVC</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.75</td>\n",
       "      <td>13.55</td>\n",
       "      <td>5.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>8.85</td>\n",
       "      <td>3.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.77</td>\n",
       "      <td>17.73</td>\n",
       "      <td>7.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>45.11</td>\n",
       "      <td>24.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.88</td>\n",
       "      <td>19.97</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>4</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.16</td>\n",
       "      <td>7.33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>4</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.01</td>\n",
       "      <td>15.76</td>\n",
       "      <td>8.84</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>3</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.29</td>\n",
       "      <td>5.30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>3</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.20</td>\n",
       "      <td>17.91</td>\n",
       "      <td>7.25</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>4</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.10</td>\n",
       "      <td>15.36</td>\n",
       "      <td>6.54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sales  Stock Remaining (%)  Avg_consumption Rate (%)  Price    AVC  \\\n",
       "0         93                 0.07                      0.75  13.55   5.15   \n",
       "1        100                 0.00                      1.00   8.85   3.92   \n",
       "2         81                 0.19                      0.77  17.73   7.54   \n",
       "3        100                 0.00                      0.99  45.11  24.98   \n",
       "4         99                 0.01                      0.88  19.97   6.71   \n",
       "...      ...                  ...                       ...    ...    ...   \n",
       "99995      4                 0.96                      0.00  14.16   7.33   \n",
       "99996      4                 0.96                      0.01  15.76   8.84   \n",
       "99997      3                 0.97                      0.00  10.29   5.30   \n",
       "99998      3                 0.97                      0.20  17.91   7.25   \n",
       "99999      4                 0.96                      0.10  15.36   6.54   \n",
       "\n",
       "       Label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "99995      3  \n",
       "99996      3  \n",
       "99997      3  \n",
       "99998      3  \n",
       "99999      3  \n",
       "\n",
       "[100000 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "Data = pd.read_csv(\"food_wastage_classification_dataset_total.csv\")\n",
    "Data = Data.drop([\"Category\"], axis=1)\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "Data = Data.drop([\"AVC\", \"Price\"], axis=1) # Greta will only have 3 input features\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.3000e+01, 7.0000e-02, 7.5000e-01],\n",
       "        [1.0000e+02, 0.0000e+00, 1.0000e+00],\n",
       "        [8.1000e+01, 1.9000e-01, 7.7000e-01],\n",
       "        ...,\n",
       "        [3.0000e+00, 9.7000e-01, 0.0000e+00],\n",
       "        [3.0000e+00, 9.7000e-01, 2.0000e-01],\n",
       "        [4.0000e+00, 9.6000e-01, 1.0000e-01]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Data.drop([\"Label\"], axis=1)\n",
    "X = torch.tensor(X.values, dtype=torch.float32)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = Data[\"Label\"]\n",
    "Y = torch.tensor(Y.values, dtype=torch.long)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = FoodDataset(X, Y)\n",
    "TrainingData, TestingData, ValidationData = random_split(Dataset, [0.7, 0.2, 0.1])\n",
    "\n",
    "TrainLoader = DataLoader(TrainingData, batch_size=BATCH_SIZE, shuffle=True)\n",
    "TestLoader = DataLoader(TestingData, batch_size=BATCH_SIZE, shuffle=False)\n",
    "ValidationLoader = DataLoader(ValidationData, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Greta(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.FoodWastageConsultant = nn.Sequential(\n",
    "            nn.Linear(3, 16),\n",
    "            nn.LeakyReLU(negative_slope=0.01),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.FoodWastageConsultant(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        return torch.argmax(self.FoodWastageConsultant(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "Consultant      = Greta()\n",
    "Optimizer       = Adam(Consultant.parameters(), lr=0.001, weight_decay=0.01)\n",
    "CostFunction    = nn.CrossEntropyLoss()\n",
    "Scheduler       = ExponentialLR(Optimizer, gamma=0.5) # To prevent overfitting the model we will use this to exponentially decrease the learning rate every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1094/1094 [00:03<00:00, 291.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Avg. Training Loss: 0.0007, Training Accuracy 67.74714285714286%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:00<00:00, 599.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7, Avg. Validation Loss: 0.2501, Validation Accuracy 94.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1094/1094 [00:03<00:00, 303.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7, Avg. Training Loss: 0.0002, Training Accuracy 94.45714285714286%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:00<00:00, 696.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/7, Avg. Validation Loss: 0.1798, Validation Accuracy 94.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1094/1094 [00:03<00:00, 327.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7, Avg. Training Loss: 0.0002, Training Accuracy 95.2357142857143%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:00<00:00, 687.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/7, Avg. Validation Loss: 0.1614, Validation Accuracy 95.13000000000001%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1094/1094 [00:03<00:00, 317.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7, Avg. Training Loss: 0.0001, Training Accuracy 95.56428571428572%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:00<00:00, 667.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7, Avg. Validation Loss: 0.1542, Validation Accuracy 95.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1094/1094 [00:03<00:00, 321.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7, Avg. Training Loss: 0.0001, Training Accuracy 95.67857142857143%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:00<00:00, 754.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/7, Avg. Validation Loss: 0.1518, Validation Accuracy 95.50999999999999%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1094/1094 [00:04<00:00, 257.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7, Avg. Training Loss: 0.0001, Training Accuracy 95.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:00<00:00, 688.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/7, Avg. Validation Loss: 0.1495, Validation Accuracy 95.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1094/1094 [00:03<00:00, 324.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7, Avg. Training Loss: 0.0001, Training Accuracy 95.81857142857143%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 157/157 [00:00<00:00, 748.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7, Avg. Validation Loss: 0.1489, Validation Accuracy 95.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # Another library which just shows us % done of loops\n",
    "\n",
    "# Training Loop\n",
    "NUMEPOCHS = 7\n",
    "\n",
    "for i in range(NUMEPOCHS):\n",
    "    # Training Loop\n",
    "    Consultant.train()\n",
    "    TrainingLoss     = 0\n",
    "    TrainingAccuracy = 0\n",
    "\n",
    "    for batch in tqdm(TrainLoader, desc=\"Training\"):\n",
    "        x, y = batch\n",
    "        \n",
    "        # Do the forwards pass on our model to find out the error\n",
    "        y_hat = Consultant(x)\n",
    "\n",
    "        # Calculate the cost\n",
    "        Cost = CostFunction(y_hat, y)\n",
    "\n",
    "        # Backwards pass\n",
    "        Optimizer.zero_grad()\n",
    "        Cost.backward()\n",
    "        Optimizer.step()\n",
    "\n",
    "        # Record Loss and Accuracy\n",
    "        TrainingLoss += Cost.item()\n",
    "        TrainingAccuracy += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    TrainingAccuracy /= len(TrainLoader.dataset)\n",
    "    TrainingLoss     /= len(TrainLoader)\n",
    "\n",
    "    print(f\"Epoch {i + 1}/{NUMEPOCHS}, Avg. Training Loss: {(TrainingLoss / len(TrainLoader)):.4f}, Training Accuracy {TrainingAccuracy * 100}%\")\n",
    "\n",
    "    # For Validation loop it's pretty much the same\n",
    "    Consultant.eval()\n",
    "    ValidationLoss     = 0\n",
    "    ValidationAccuracy = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(ValidationLoader, desc=\"Validating\"):\n",
    "            x, y = batch\n",
    "\n",
    "            # Do the forwards pass on our model to find out the error\n",
    "            y_hat = Consultant(x)\n",
    "\n",
    "            # Calculate the cost\n",
    "            ValidationCost = CostFunction(y_hat, y)\n",
    "\n",
    "            # Record loss and Accuracy\n",
    "            ValidationLoss += ValidationCost.item()\n",
    "            ValidationAccuracy += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    ValidationAccuracy /= len(ValidationLoader.dataset)\n",
    "    ValidationLoss     /= len(ValidationLoader)\n",
    "\n",
    "    print(f\"Epoch {i + 1}/{NUMEPOCHS}, Avg. Validation Loss: {(ValidationLoss):.4f}, Validation Accuracy { ValidationAccuracy * 100}%\")\n",
    "\n",
    "    # Adjust Learning Rate\n",
    "    Scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 313/313 [00:00<00:00, 700.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/7, Avg. Testing Loss: 0.1461, Testing Accuracy 95.92500000000001%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Consultant.eval()\n",
    "TestingLoss     = 0\n",
    "TestingAccuracy = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(TestLoader, desc=\"Testing\"):\n",
    "        x, y = batch\n",
    "\n",
    "        # Do the forwards pass on our model to find out the error\n",
    "        y_hat = Consultant(x)\n",
    "\n",
    "        # Calculate the cost\n",
    "        TestingCost = CostFunction(y_hat, y)\n",
    "\n",
    "        # Record loss and Accuracy\n",
    "        TestingLoss += TestingCost.item()\n",
    "        TestingAccuracy += (y_hat.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "TestingAccuracy /= len(TestLoader.dataset)\n",
    "TestingLoss     /= len(TestLoader)\n",
    "\n",
    "print(f\"Epoch {i + 1}/{NUMEPOCHS}, Avg. Testing Loss: {(TestingLoss):.4f}, Testing Accuracy { TestingAccuracy * 100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Consultant.state_dict(), \"TrainedModels/Greta.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
